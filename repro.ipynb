{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1ZlyoG7aQcCDQIuH-mnxCqcLxbDD6tfh4","authorship_tag":"ABX9TyMYM3RwWRT2iQQCJtF1finR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","*   **Please first download the CSV file from Github repo,**\n","*   **Then upload the file in the G-drive and mount them as well**\n","\n"],"metadata":{"id":"p2CLY0erxTUJ"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"z_RrLhynxKFK","executionInfo":{"status":"ok","timestamp":1745548502522,"user_tz":240,"elapsed":3322,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}}},"outputs":[],"source":["df_AAC= pd.read_csv(\"/content/drive/MyDrive/kan/AAC_all.csv\")\n","df_AESNN= pd.read_csv(\"/content/drive/MyDrive/kan/AESNN3_all.csv\")\n","df_Zscale= pd.read_csv(\"/content/drive/MyDrive/kan/Zscale_all.csv\")\n","df_Blosume= pd.read_csv(\"/content/drive/MyDrive/kan/blosume62_all.csv\")\n","df_OPF= pd.read_csv(\"/content/drive/MyDrive/kan/opf10bit_all.csv\")\n","df_merged= pd.read_csv(\"/content/drive/MyDrive/kan/merged all.csv\")\n","df_neuroAAC= pd.read_csv(\"/content/drive/MyDrive/Antifungal code/Neuropeptide/aactrain.csv\")"]},{"cell_type":"markdown","source":["**KAN [ kormologov analond model ]**\n","installation procedure from pykan doccumentation, for more details :  https://kindxiaoming.github.io/pykan/Examples/Example_3_classfication.html\n","\n","**Requirment:**\n","\n","\n","*   torch==2.2.1+cu121\n","\n","\n","---\n","\n","\n","*  matplotlib==3.7.1\n","\n","\n","---\n","\n","\n","\n","*   sklearn==1.2.2\n","\n","\n","---\n","\n","\n","\n","*   moviepy==1.0.3\n","\n","\n"],"metadata":{"id":"etwCvUamx7xw"}},{"cell_type":"code","source":["!pip install pykan"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bi_LYaLeyP_w","executionInfo":{"status":"ok","timestamp":1745548290311,"user_tz":240,"elapsed":4142,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}},"outputId":"0dcfc329-dbc7-4cd6-d00e-9a389a7bfee2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pykan\n","  Downloading pykan-0.2.8-py3-none-any.whl.metadata (11 kB)\n","Downloading pykan-0.2.8-py3-none-any.whl (78 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.1/78.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pykan\n","Successfully installed pykan-0.2.8\n"]}]},{"cell_type":"markdown","source":["**Check CUDA and CPU**\n","```\n","1.   if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","2.   else:\n","  device = torch.device(\"cpu\")\n","\n","print(device)\n","\n","```\n","\n","\n","\n"],"metadata":{"id":"4vQuy2EIyeWg"}},{"cell_type":"code","source":["import torch\n","from kan import *\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","import moviepy.video.io.ImageSequenceClip\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMP0cwvIyUqH","executionInfo":{"status":"ok","timestamp":1745548322736,"user_tz":240,"elapsed":6903,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}},"outputId":"83cb6675-9da8-487a-f2f4-bdc215eb57a6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score, precision_score, recall_score, f1_score\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"ZXwOZTB3yG7_","executionInfo":{"status":"ok","timestamp":1745548281073,"user_tz":240,"elapsed":15761,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Convert to PyTorch tensors\n","---\n","Concatenate all data into a single tensor on the specified device\n","---\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"WZOMdWrAzMzI"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"1ZYTkok2IvWY","executionInfo":{"status":"ok","timestamp":1745548513677,"user_tz":240,"elapsed":8,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}}},"outputs":[],"source":["\n","import csv\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","def load_iris_dataset(csv_file):\n","\n","    iris = pd.read_csv(csv_file)\n","    data_tensor = torch.tensor(iris.iloc[:, :-1].values, dtype=torch.float)\n","    target_tensor = torch.tensor(iris.iloc[:, -1].values, dtype=torch.long)\n","\n","    # Convert to PyTorch tensors\n","    #data_tensor = torch.tensor(data, dtype=torch.float32)\n","    #target_tensor = torch.tensor(target, dtype=torch.long)\n","\n","    # Split dataset into train and test sets\n","    train_data= train, test_data, train_target, test_target = train_test_split(data_tensor, target_tensor, test_size=0.2, random_state=42)\n","\n","    # Create data loaders (optional, if you want to batch and shuffle the data)\n","    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=1, shuffle=True)\n","    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=1, shuffle=False)\n","\n","    train_inputs = torch.empty(0, 1168, device=device)\n","    train_labels = torch.empty(0, dtype=torch.long, device=device)\n","    test_inputs = torch.empty(0, 1168, device=device)\n","    test_labels = torch.empty(0, dtype=torch.long, device=device)\n","\n","    # Concatenate all data into a single tensor on the specified device\n","    for data, labels in train_loader:\n","        train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n","        train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n","\n","    for data, labels in test_loader:\n","        test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n","        test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n","\n","    dataset = {}\n","    dataset['train_input'] = train_inputs\n","    dataset['test_input'] = test_inputs\n","    dataset['train_label'] = train_labels\n","    dataset['test_label'] = test_labels\n","\n","    return dataset\n","\n","iris_dataset = df_Zscale"]},{"cell_type":"code","source":[],"metadata":{"id":"6vCQBkVz2Yng"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1745549379727,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"},"user_tz":240},"id":"AccH1fCXYSX-","outputId":"5f6421c5-a133-4c56-c31c-f8d5b3267c57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1\n","Train data shape: torch.Size([362, 155])\n","Train target shape: torch.Size([362])\n","Test data shape: torch.Size([41, 155])\n","Test target shape: torch.Size([41])\n","Fold 2\n","Train data shape: torch.Size([362, 155])\n","Train target shape: torch.Size([362])\n","Test data shape: torch.Size([41, 155])\n","Test target shape: torch.Size([41])\n","Fold 3\n","Train data shape: torch.Size([362, 155])\n","Train target shape: torch.Size([362])\n","Test data shape: torch.Size([41, 155])\n","Test target shape: torch.Size([41])\n","Fold 4\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 5\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 6\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 7\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 8\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 9\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n","Fold 10\n","Train data shape: torch.Size([363, 155])\n","Train target shape: torch.Size([363])\n","Test data shape: torch.Size([40, 155])\n","Test target shape: torch.Size([40])\n"]}],"source":["import csv\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from sklearn.model_selection import KFold\n","\n","def load_iris_dataset(csv_file):\n","    # Load the dataset\n","    iris = df_Zscale\n","    data_tensor = torch.tensor(iris.iloc[:, :-1].values, dtype=torch.float)\n","    target_tensor = torch.tensor(iris.iloc[:, -1].values, dtype=torch.long)\n","\n","    # Use KFold for cross-validation\n","    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    dataset = {\n","        'folds': []\n","    }\n","\n","    # Iterate through each fold\n","    for fold, (train_indices, test_indices) in enumerate(kfold.split(data_tensor)):\n","        # Split data\n","        train_data, test_data = data_tensor[train_indices], data_tensor[test_indices]\n","        train_target, test_target = target_tensor[train_indices], target_tensor[test_indices]\n","\n","        # Create data loaders\n","        train_loader = DataLoader(TensorDataset(train_data, train_target), batch_size=10, shuffle=True)\n","        test_loader = DataLoader(TensorDataset(test_data, test_target), batch_size=10, shuffle=True)\n","\n","        train_inputs = torch.empty(0, train_data.size(1), device=device)\n","        train_labels = torch.empty(0, dtype=torch.long, device=device)\n","        test_inputs = torch.empty(0, test_data.size(1), device=device)\n","        test_labels = torch.empty(0, dtype=torch.long, device=device)\n","\n","        # Concatenate all data into a single tensor on the specified device\n","        for data, labels in train_loader:\n","            train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n","            train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n","\n","        for data, labels in test_loader:\n","            test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n","            test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n","\n","        # Append the fold data to the dataset\n","        dataset['folds'].append({\n","            'train_input': train_inputs,\n","            'test_input': test_inputs,\n","            'train_label': train_labels,\n","            'test_label': test_labels\n","        })\n","\n","    return dataset\n","\n","# Correctly calling the function\n","csv_file = df_Zscale\n","iris_dataset = load_iris_dataset(csv_file)\n","\n","# Printing the shapes of the data tensors for each fold\n","for fold_idx, fold_data in enumerate(iris_dataset['folds']):\n","    print(f\"Fold {fold_idx + 1}\")\n","    print(\"Train data shape: {}\".format(fold_data['train_input'].shape))\n","    print(\"Train target shape: {}\".format(fold_data['train_label'].shape))\n","    print(\"Test data shape: {}\".format(fold_data['test_input'].shape))\n","    print(\"Test target shape: {}\".format(fold_data['test_label'].shape))\n"]},{"cell_type":"markdown","source":["# Model applied of each feature extraction method\n","we used here 10 fold cross validation methods:\n","\n","▶ where `model = KAN(width=[155, 5, 2], device='cuda' if torch.cuda.is_available() else 'cpu')`\n","here  in width [155= features number, 5= hidden layers,and  2= output layers, we used 2 cause we have a 0 and 1 binary classification dataset]\n","\n","▶ most importantly here all the feature extraction methods have used **5= hidden layers,and  2= output layers** and feature number used based on the *quantity of the features*\n","\n","\n","▶ Train the model  with `for epoch in range(400)` see the code and comments also\n","\n","▶ Calculate **mean and standard deviation** of metrics"],"metadata":{"id":"FFFrgm6-yFRH"}},{"cell_type":"code","source":["class KAN(torch.nn.Module):\n","    def __init__(self, width, device):\n","        super(KAN, self).__init__()\n","        self.layers = torch.nn.Sequential(\n","            torch.nn.Linear(width[0], width[1]),\n","            torch.nn.ReLU(),\n","            torch.nn.Linear(width[1], width[2])\n","        )\n","        self.device = device\n","        self.to(device)\n","\n","    def forward(self, x):\n","        return self.layers(x)"],"metadata":{"id":"IWlzvOMsx_bv","executionInfo":{"status":"ok","timestamp":1745549406387,"user_tz":240,"elapsed":11,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8718,"status":"ok","timestamp":1745549494160,"user":{"displayName":"Md. Shazzad Hossain Shaon","userId":"02845614164894743268"},"user_tz":240},"id":"g8zpMZ2WVtQw","outputId":"08d37659-7980-4b47-b0df-03f87adabfa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Accuracy: 0.9760 ± 0.0079\n","Test Accuracy: 0.9145 ± 0.1367\n","Train Sensitivity: 0.9419 ± 0.0073\n","Test Sensitivity: 0.8763 ± 0.1862\n","Train Specificity: 0.9969 ± 0.0093\n","Test Specificity: 0.9457 ± 0.1066\n","Train AUC: 0.9911 ± 0.0043\n","Test AUC: 0.9393 ± 0.1070\n","Train MCC: 0.9495 ± 0.0171\n","Test MCC: 0.8280 ± 0.2774\n","Train Kappa: 0.9486 ± 0.0169\n","Test Kappa: 0.8238 ± 0.2813\n","Train Precision: 0.9802 ± 0.0095\n","Test Precision: 0.9172 ± 0.1369\n","Train Recall: 0.9694 ± 0.0076\n","Test Recall: 0.9110 ± 0.1406\n","Train F1 Score: 0.9743 ± 0.0084\n","Test F1 Score: 0.9110 ± 0.1417\n"]}],"source":["import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score, precision_score, recall_score, f1_score\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","\n","model = KAN(width=[155, 5, 2], device='cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","\n","\n","def train_model(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, dataset, device):\n","    def to_cpu(tensor):\n","        return tensor.detach().cpu().numpy()\n","\n","    def accuracy(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return (preds == labels).float().mean().item()\n","\n","    def sensitivity(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        tn, fp, fn, tp = confusion_matrix(labels.cpu(), preds.cpu()).ravel()\n","        return tp / (tp + fn)\n","\n","    def specificity(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        tn, fp, fn, tp = confusion_matrix(labels.cpu(), preds.cpu()).ravel()\n","        return tn / (tn + fp)\n","\n","    def auc_score(outputs, labels):\n","        preds = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n","        return roc_auc_score(labels.cpu(), preds.cpu())\n","\n","    def mcc_score(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return matthews_corrcoef(labels.cpu(), preds.cpu())\n","\n","    def kappa_score(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return cohen_kappa_score(labels.cpu(), preds.cpu())\n","\n","    def precision(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return precision_score(labels.cpu(), preds.cpu(), average='macro')\n","\n","    def recall(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return recall_score(labels.cpu(), preds.cpu(), average='macro')\n","\n","    def f1(outputs, labels):\n","        preds = torch.argmax(outputs, dim=1)\n","        return f1_score(labels.cpu(), preds.cpu(), average='macro')\n","\n","    metrics = {\n","        'accuracy': accuracy,\n","        'sensitivity': sensitivity,\n","        'specificity': specificity,\n","        'auc': auc_score,\n","        'mcc': mcc_score,\n","        'kappa': kappa_score,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","    results = {f'train_{k}_list': [] for k in metrics.keys()}\n","    results.update({f'test_{k}_list': [] for k in metrics.keys()})\n","\n","    for fold_data in dataset['folds']:\n","        train_inputs, train_labels = fold_data['train_input'], fold_data['train_label']\n","        test_inputs, test_labels = fold_data['test_input'], fold_data['test_label']\n","\n","        # Prepare data loaders\n","        train_dataset = TensorDataset(train_inputs, train_labels)\n","        test_dataset = TensorDataset(test_inputs, test_labels)\n","        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","        # Define criterion and optimizer\n","        criterion = torch.nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","        # Train the model\n","        for epoch in range(40):  # with 400 epoch\n","            train_model(model, train_loader, criterion, optimizer, device)\n","\n","        # Evaluate on training and testing data\n","        model.eval()\n","        with torch.no_grad():\n","            train_outputs = model(train_inputs.to(device))\n","            test_outputs = model(test_inputs.to(device))\n","\n","        for metric_name, metric_func in metrics.items():\n","            train_metric_value = metric_func(train_outputs, train_labels.to(device))\n","            test_metric_value = metric_func(test_outputs, test_labels.to(device))\n","            results[f'train_{metric_name}_list'].append(train_metric_value)\n","            results[f'test_{metric_name}_list'].append(test_metric_value)\n","\n","    # Calculate mean and standard deviation of metrics\n","    summary_results = {}\n","    for metric_name in metrics.keys():\n","        summary_results[f'train_{metric_name}_mean'] = np.mean(results[f'train_{metric_name}_list'])\n","        summary_results[f'train_{metric_name}_std'] = np.std(results[f'train_{metric_name}_list'])\n","        summary_results[f'test_{metric_name}_mean'] = np.mean(results[f'test_{metric_name}_list'])\n","        summary_results[f'test_{metric_name}_std'] = np.std(results[f'test_{metric_name}_list'])\n","\n","    return summary_results\n","\n","def load_iris_dataset(df_Zscale):\n","\n","    # Convert the DataFrame to TensorDataset\n","    X = df_Zscale.iloc[:, :-1].values\n","    y = df_Zscale.iloc[:, -1].values\n","    X = StandardScaler().fit_transform(X)\n","    X = torch.tensor(X, dtype=torch.float32)\n","    y = torch.tensor(y, dtype=torch.long)\n","\n","    # Create K-Folds\n","    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n","    folds = []\n","    for train_idx, test_idx in kfold.split(X):\n","        folds.append({\n","            'train_input': X[train_idx],\n","            'train_label': y[train_idx],\n","            'test_input': X[test_idx],\n","            'test_label': y[test_idx]\n","        })\n","    return {'folds': folds}\n","\n","iris_dataset = load_iris_dataset(df_Zscale)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","results = evaluate_model(model, iris_dataset, device)\n","print(\"Train Accuracy: {:.4f} ± {:.4f}\".format(results['train_accuracy_mean'], results['train_accuracy_std']))\n","print(\"Test Accuracy: {:.4f} ± {:.4f}\".format(results['test_accuracy_mean'], results['test_accuracy_std']))\n","print(\"Train Sensitivity: {:.4f} ± {:.4f}\".format(results['train_sensitivity_mean'], results['train_sensitivity_std']))\n","print(\"Test Sensitivity: {:.4f} ± {:.4f}\".format(results['test_sensitivity_mean'], results['test_sensitivity_std']))\n","print(\"Train Specificity: {:.4f} ± {:.4f}\".format(results['train_specificity_mean'], results['train_specificity_std']))\n","print(\"Test Specificity: {:.4f} ± {:.4f}\".format(results['test_specificity_mean'], results['test_specificity_std']))\n","print(\"Train AUC: {:.4f} ± {:.4f}\".format(results['train_auc_mean'], results['train_auc_std']))\n","print(\"Test AUC: {:.4f} ± {:.4f}\".format(results['test_auc_mean'], results['test_auc_std']))\n","print(\"Train MCC: {:.4f} ± {:.4f}\".format(results['train_mcc_mean'], results['train_mcc_std']))\n","print(\"Test MCC: {:.4f} ± {:.4f}\".format(results['test_mcc_mean'], results['test_mcc_std']))\n","print(\"Train Kappa: {:.4f} ± {:.4f}\".format(results['train_kappa_mean'], results['train_kappa_std']))\n","print(\"Test Kappa: {:.4f} ± {:.4f}\".format(results['test_kappa_mean'], results['test_kappa_std']))\n","print(\"Train Precision: {:.4f} ± {:.4f}\".format(results['train_precision_mean'], results['train_precision_std']))\n","print(\"Test Precision: {:.4f} ± {:.4f}\".format(results['test_precision_mean'], results['test_precision_std']))\n","print(\"Train Recall: {:.4f} ± {:.4f}\".format(results['train_recall_mean'], results['train_recall_std']))\n","print(\"Test Recall: {:.4f} ± {:.4f}\".format(results['test_recall_mean'], results['test_recall_std']))\n","print(\"Train F1 Score: {:.4f} ± {:.4f}\".format(results['train_f1_mean'], results['train_f1_std']))\n","print(\"Test F1 Score: {:.4f} ± {:.4f}\".format(results['test_f1_mean'], results['test_f1_std']))\n"]}]}